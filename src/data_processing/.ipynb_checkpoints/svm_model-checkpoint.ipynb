{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import csv\n",
    "import glob\n",
    "from shutil import copyfile\n",
    "\n",
    "def organize_data():\n",
    "    '''This function sorts the downloaded folder structure so that a subdirectory for each emotion is populated\n",
    "    with their corresponding images.'''\n",
    "\n",
    "    emotions = [\"neutral\", \"anger\", \"contempt\", \"disgust\", \"fear\", \"happy\", \"sadness\", \"surprise\"] #Define emotion order\n",
    "    participants = glob.glob(\"source_emotion//*\") #Returns a list of all folders with participant numbers\n",
    "    for x in participants:\n",
    "        part = \"%s\" %x[-4:] #store current participant number\n",
    "        for sessions in glob.glob(\"%s//*\" %x): #Store list of sessions for current participant\n",
    "            for files in glob.glob(\"%s//*\" %sessions):\n",
    "                current_session = files[20:-30]\n",
    "\n",
    "                with open(files, 'r') as f:\n",
    "                    file = f.read()\n",
    "                emotion = int(float(file)) #emotions are encoded as a float, readline as float, then convert to integer.\n",
    "                sourcefile_emotion = sorted(glob.glob(\"source_images/%s/%s/*\" %(part, current_session)))[-1] #get path for last image in sequence, which contains the emotion\n",
    "                sourcefile_neutral = sorted(glob.glob(\"source_images/%s/%s/*\" %(part, current_session)))[0] #do same for neutral image\n",
    "                dest_neut = \"sorted_set//neutral//%s\" %sourcefile_neutral[25:] #Generate path to put neutral image\n",
    "                dest_emot = \"sorted_set//%s//%s\" %(emotions[emotion], sourcefile_emotion[25:]) #Do same for emotion containing image\n",
    "                copyfile(sourcefile_neutral, dest_neut) #Copy file\n",
    "                copyfile(sourcefile_emotion, dest_emot) #Copy file\n",
    "\n",
    "organize_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/cmeaton/Documents/code/ds/METIS/sea19_ds7_workingdir/project_5/data/external/cohn_dataset\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making sets 0\n",
      " working on anger\n",
      " working on contempt\n",
      " working on disgust\n",
      " working on fear\n",
      " working on happiness\n",
      " working on neutral\n",
      " working on sadness\n",
      " working on surprise\n",
      "training SVM linear 0\n",
      "getting accuracies 0\n",
      "linear: 0.8247422680412371\n",
      "Making sets 1\n",
      " working on anger\n",
      " working on contempt\n",
      " working on disgust\n",
      " working on fear\n",
      " working on happiness\n",
      " working on neutral\n",
      " working on sadness\n",
      " working on surprise\n",
      "training SVM linear 1\n",
      "getting accuracies 1\n",
      "linear: 0.8865979381443299\n",
      "Making sets 2\n",
      " working on anger\n",
      " working on contempt\n",
      " working on disgust\n",
      " working on fear\n",
      " working on happiness\n",
      " working on neutral\n",
      " working on sadness\n",
      " working on surprise\n",
      "training SVM linear 2\n",
      "getting accuracies 2\n",
      "linear: 0.8144329896907216\n",
      "Making sets 3\n",
      " working on anger\n",
      " working on contempt\n",
      " working on disgust\n",
      " working on fear\n",
      " working on happiness\n",
      " working on neutral\n",
      " working on sadness\n",
      " working on surprise\n",
      "training SVM linear 3\n",
      "getting accuracies 3\n",
      "linear: 0.845360824742268\n",
      "Making sets 4\n",
      " working on anger\n",
      " working on contempt\n",
      " working on disgust\n",
      " working on fear\n",
      " working on happiness\n",
      " working on neutral\n",
      " working on sadness\n",
      " working on surprise\n",
      "training SVM linear 4\n",
      "getting accuracies 4\n",
      "linear: 0.8350515463917526\n",
      "Making sets 5\n",
      " working on anger\n",
      " working on contempt\n",
      " working on disgust\n",
      " working on fear\n",
      " working on happiness\n",
      " working on neutral\n",
      " working on sadness\n",
      " working on surprise\n",
      "training SVM linear 5\n",
      "getting accuracies 5\n",
      "linear: 0.7319587628865979\n",
      "Making sets 6\n",
      " working on anger\n",
      " working on contempt\n",
      " working on disgust\n",
      " working on fear\n",
      " working on happiness\n",
      " working on neutral\n",
      " working on sadness\n",
      " working on surprise\n",
      "training SVM linear 6\n",
      "getting accuracies 6\n",
      "linear: 0.8865979381443299\n",
      "Making sets 7\n",
      " working on anger\n",
      " working on contempt\n",
      " working on disgust\n",
      " working on fear\n",
      " working on happiness\n",
      " working on neutral\n",
      " working on sadness\n",
      " working on surprise\n",
      "training SVM linear 7\n",
      "getting accuracies 7\n",
      "linear: 0.7938144329896907\n",
      "Making sets 8\n",
      " working on anger\n",
      " working on contempt\n",
      " working on disgust\n",
      " working on fear\n",
      " working on happiness\n",
      " working on neutral\n",
      " working on sadness\n",
      " working on surprise\n",
      "training SVM linear 8\n",
      "getting accuracies 8\n",
      "linear: 0.8350515463917526\n",
      "Making sets 9\n",
      " working on anger\n",
      " working on contempt\n",
      " working on disgust\n",
      " working on fear\n",
      " working on happiness\n",
      " working on neutral\n",
      " working on sadness\n",
      " working on surprise\n",
      "training SVM linear 9\n",
      "getting accuracies 9\n",
      "linear: 0.8144329896907216\n",
      "Mean value lin svm: 0.8268041237113402\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import dlib\n",
    "import itertools\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "emotions = [\"anger\", \"contempt\", \"disgust\", \"fear\", \"happiness\", \"neutral\", \"sadness\", \"surprise\"] #Emotion list\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"/Users/cmeaton/Documents/code/ds/METIS/sea19_ds7_workingdir/project_5/src/models/shape_predictor_68_face_landmarks.dat\")\n",
    "clf = SVC(kernel='linear', probability=True, tol=1e-3)#, verbose = True) #Set the classifier as a support vector machines with polynomial kernel\n",
    "data = {} #Make dictionary for all values\n",
    "#data['landmarks_vectorised'] = []\n",
    "\n",
    "\n",
    "def get_files(emotion): #Define function to get file list, randomly shuffle it and split 80/20\n",
    "    files = glob.glob(\"data_set/%s/*\" %emotion)\n",
    "    random.shuffle(files)\n",
    "    training = files[:int(len(files)*0.8)] #get first 80% of file list\n",
    "    prediction = files[-int(len(files)*0.2):] #get last 20% of file list\n",
    "    return training, prediction\n",
    "\n",
    "def get_landmarks(image):\n",
    "    detections = detector(image, 1)\n",
    "    for k,d in enumerate(detections): #For all detected face instances individually\n",
    "        shape = predictor(image, d) #Draw Facial Landmarks with the predictor class\n",
    "        xlist = []\n",
    "        ylist = []\n",
    "        for i in range(1,68): #Store X and Y coordinates in two lists\n",
    "            xlist.append(float(shape.part(i).x))\n",
    "            ylist.append(float(shape.part(i).y))\n",
    "        xmean = np.mean(xlist)\n",
    "        ymean = np.mean(ylist)\n",
    "        xcentral = [(x-xmean) for x in xlist]\n",
    "        ycentral = [(y-ymean) for y in ylist]\n",
    "        landmarks_vectorised = []\n",
    "        for x, y, w, z in zip(xcentral, ycentral, xlist, ylist):\n",
    "            landmarks_vectorised.append(w)\n",
    "            landmarks_vectorised.append(z)\n",
    "            meannp = np.asarray((ymean,xmean))\n",
    "            coornp = np.asarray((z,w))\n",
    "            dist = np.linalg.norm(coornp-meannp)\n",
    "            landmarks_vectorised.append(dist)\n",
    "            landmarks_vectorised.append((math.atan2(y, x)*360)/(2*math.pi))\n",
    "        data['landmarks_vectorised'] = landmarks_vectorised\n",
    "    if len(detections) < 1:\n",
    "        data['landmarks_vestorised'] = \"error\"\n",
    "\n",
    "def make_sets():\n",
    "    \n",
    "    \n",
    "    training_data = []\n",
    "    training_labels = []\n",
    "    prediction_data = []\n",
    "    prediction_labels = []\n",
    "    for emotion in emotions:\n",
    "        print(\" working on %s\" %emotion)\n",
    "        training, prediction = get_files(emotion)\n",
    "        #Append data to training and prediction list, and generate labels 0-7\n",
    "        for item in training:\n",
    "            image = cv2.imread(item) #open image\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) #convert to grayscale\n",
    "            clahe_image = clahe.apply(gray)\n",
    "            get_landmarks(clahe_image)\n",
    "            if data['landmarks_vectorised'] == \"error\":\n",
    "                print(\"no face detected on this one\")\n",
    "            else:\n",
    "                training_data.append(data['landmarks_vectorised']) #append image array to training data list\n",
    "                training_labels.append(emotions.index(emotion))\n",
    "        for item in prediction:\n",
    "            image = cv2.imread(item)\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            clahe_image = clahe.apply(gray)\n",
    "            get_landmarks(clahe_image)\n",
    "            if data['landmarks_vectorised'] == \"error\":\n",
    "                print(\"no face detected on this one\")\n",
    "            else:\n",
    "                prediction_data.append(data['landmarks_vectorised'])\n",
    "                prediction_labels.append(emotions.index(emotion))\n",
    "    return training_data, training_labels, prediction_data, prediction_labels\n",
    "\n",
    "\n",
    "accur_lin = []\n",
    "for i in range(0,10):\n",
    "    print(\"Making sets %s\" %i) #Make sets by random sampling 80/20%\n",
    "    training_data, training_labels, prediction_data, prediction_labels = make_sets()\n",
    "    npar_train = np.array(training_data) #Turn the training set into a numpy array for the classifier\n",
    "    npar_trainlabs = np.array(training_labels)\n",
    "    print(\"training SVM linear %s\" %i) #train SVM\n",
    "    clf.fit(npar_train, training_labels)\n",
    "    print(\"getting accuracies %s\" %i) #Use score() function to get accuracy\n",
    "    npar_pred = np.array(prediction_data)\n",
    "    pred_lin = clf.score(npar_pred, prediction_labels)\n",
    "    print(f\"linear: {pred_lin}\")\n",
    "    accur_lin.append(pred_lin) #Store accuracy in a list\n",
    "print(\"Mean value lin svm: %s\" %np.mean(accur_lin)) #FGet mean accuracy of the 10 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=True, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'lin_svm_model.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=nan.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-5cabd4d2f036>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mpredicted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'IMG_3388.JPG'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-47-5cabd4d2f036>\u001b[0m in \u001b[0;36mpredicted\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mclahe_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclahe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mget_landmarks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclahe_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_landmarks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclahe_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/affective_image/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobA_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobB_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m             raise NotFittedError(\"predict_proba is not available when fitted \"\n",
      "\u001b[0;32m~/anaconda3/envs/affective_image/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         X = check_array(X, accept_sparse='csr', dtype=np.float64, order=\"C\",\n\u001b[0;32m--> 458\u001b[0;31m                         accept_large_sparse=False)\n\u001b[0m\u001b[1;32m    459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/affective_image/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    538\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    541\u001b[0m             \u001b[0;31m# If input is 1D raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray=nan.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "def predicted(img):\n",
    "    \n",
    "    image = cv2.imread(img)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    clahe_image = clahe.apply(gray)\n",
    "    get_landmarks(clahe_image)\n",
    "    return loaded_model.predict_proba(get_landmarks(clahe_image))\n",
    "\n",
    "                               \n",
    "predicted('IMG_3388.JPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
