{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from shutil import copyfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "def organize_data():\n",
    "    '''This function sorts the downloaded folder structure so that a subdirectory for each emotion is populated\n",
    "    with their corresponding images.'''\n",
    "\n",
    "    emotions = [\"neutral\", \"anger\", \"contempt\", \"disgust\", \"fear\", \"happy\", \"sadness\", \"surprise\"] #Define emotion order\n",
    "    participants = glob.glob(\"source_emotion//*\") #Returns a list of all folders with participant numbers\n",
    "    for x in participants:\n",
    "        part = \"%s\" %x[-4:] #store current participant number\n",
    "        for sessions in glob.glob(\"%s//*\" %x): #Store list of sessions for current participant\n",
    "            for files in glob.glob(\"%s//*\" %sessions):\n",
    "                current_session = files[20:-30]\n",
    "\n",
    "                with open(files, 'r') as f:\n",
    "                    file = f.read()\n",
    "                emotion = int(float(file)) #emotions are encoded as a float, readline as float, then convert to integer.\n",
    "                sourcefile_emotion = sorted(glob.glob(\"source_images/%s/%s/*\" %(part, current_session)))[-1] #get path for last image in sequence, which contains the emotion\n",
    "                sourcefile_neutral = sorted(glob.glob(\"source_images/%s/%s/*\" %(part, current_session)))[0] #do same for neutral image\n",
    "                dest_neut = \"sorted_set//neutral//%s\" %sourcefile_neutral[25:] #Generate path to put neutral image\n",
    "                dest_emot = \"sorted_set//%s//%s\" %(emotions[emotion], sourcefile_emotion[25:]) #Do same for emotion containing image\n",
    "                copyfile(sourcefile_neutral, dest_neut) #Copy file\n",
    "                copyfile(sourcefile_emotion, dest_emot) #Copy file\n",
    "\n",
    "organize_data()\n",
    "\n",
    "faceDet = cv2.CascadeClassifier('/Users/cmeaton/Documents/code/opencv/data/haarcascades/haarcascade_frontalface_default.xml')\n",
    "faceDet_two = cv2.CascadeClassifier(\"/Users/cmeaton/Documents/code/opencv/data/haarcascades/haarcascade_frontalface_alt2.xml\")\n",
    "faceDet_three = cv2.CascadeClassifier(\"/Users/cmeaton/Documents/code/opencv/data/haarcascades/haarcascade_frontalface_alt.xml\")\n",
    "faceDet_four = cv2.CascadeClassifier(\"/Users/cmeaton/Documents/code/opencv/data/haarcascades/haarcascade_frontalface_alt_tree.xml\")\n",
    "\n",
    "\n",
    "\n",
    "def detect_faces(emotion):\n",
    "    \n",
    "    emotions = [\"neutral\", \"anger\", \"contempt\", \"disgust\", \"fear\", \"happy\", \"sadness\", \"surprise\"] #Define emotions\n",
    "    files = glob.glob(\"sorted_set/%s/*\" %emotion) #Get list of all images with emotion\n",
    "    filenumber = 0\n",
    "    for f in files:\n",
    "        frame = cv2.imread(f) #Open image\n",
    "#         img = tf.image.grayscale_to_rgb(frame)\n",
    "       # gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #Convert image to grayscale\n",
    "        # gray = cv2.cvtColor(frame, cv2.CV_GRAY2RGB)\n",
    "        #img = cv2.cvtColor(frame, CV_GRAY2BGR)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #Convert image to grayscale\n",
    "\n",
    "        #Detect face using 4 different classifiers\n",
    "        face = faceDet.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10, minSize=(5, 5), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        face_two = faceDet_two.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10, minSize=(5, 5), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        face_three = faceDet_three.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10, minSize=(5, 5), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        face_four = faceDet_four.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10, minSize=(5, 5), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        #Go over detected faces, stop at first detected face, return empty if no face.\n",
    "        if len(face) == 1:\n",
    "            facefeatures = face\n",
    "        elif len(face_two) == 1:\n",
    "            facefeatures = face_two\n",
    "        elif len(face_three) == 1:\n",
    "            facefeatures = face_three\n",
    "        elif len(face_four) == 1:\n",
    "            facefeatures = face_four\n",
    "        else:\n",
    "            facefeatures = \"\"\n",
    "        #Cut and save face\n",
    "        for (x, y, w, h) in facefeatures: #get coordinates and size of rectangle containing face\n",
    "            print(\"face found in file: %s\" %f)\n",
    "#             gray = gray[y:y+h, x:x+w] #Cut the frame to size\n",
    "            gray = gray[y:y+h, x:x+w] #Cut the frame to size\n",
    "\n",
    "            try:\n",
    "                out = cv2.resize(gray, (350, 350)) #Resize face so all images have same size\n",
    "                cv2.imwrite(\"dataset/%s/%s.jpg\" %(emotion, filenumber), out) #Write image\n",
    "            except:\n",
    "                pass #If error, pass file\n",
    "        filenumber += 1 #Increment image number\n",
    "\n",
    "for emotion in emotions:\n",
    "    detect_faces(emotion) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
