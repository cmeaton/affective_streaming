{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import dlib\n",
    "import itertools\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "\n",
    "filename = '/Users/cmeaton/Documents/code/ds/METIS/sea19_ds7_workingdir/project_5/src/models/lin_svm_model.sav'\n",
    "\n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=True, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/cmeaton/Documents/code/ds/METIS/sea19_ds7_workingdir/project_5/data/external/outside_testing_images/download.png'\n",
    "path1 = '/Users/cmeaton/Documents/code/ds/METIS/sea19_ds7_workingdir/project_5/data/external/cohn_dataset/sorted_set/disgust/02_009_00000015.png'\n",
    "faceDet = cv2.CascadeClassifier('/Users/cmeaton/Documents/code/opencv/data/haarcascades/haarcascade_frontalface_default.xml')\n",
    "faceDet_two = cv2.CascadeClassifier(\"/Users/cmeaton/Documents/code/opencv/data/haarcascades/haarcascade_frontalface_alt2.xml\")\n",
    "faceDet_three = cv2.CascadeClassifier(\"/Users/cmeaton/Documents/code/opencv/data/haarcascades/haarcascade_frontalface_alt.xml\")\n",
    "faceDet_four = cv2.CascadeClassifier(\"/Users/cmeaton/Documents/code/opencv/data/haarcascades/haarcascade_frontalface_alt_tree.xml\")\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"/Users/cmeaton/Documents/code/ds/METIS/sea19_ds7_workingdir/project_5/src/models/shape_predictor_68_face_landmarks.dat\")\n",
    "data = {} #Make dictionary for all values\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "\n",
    "def process_image(image_path):\n",
    "\n",
    "    frame = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = clahe.apply(gray)\n",
    "    \n",
    "    #Detect face using 4 different classifiers\n",
    "    face = faceDet.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10, minSize=(5, 5), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    face_two = faceDet_two.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10, minSize=(5, 5), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    face_three = faceDet_three.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10, minSize=(5, 5), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    face_four = faceDet_four.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10, minSize=(5, 5), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "    #Go over detected faces, stop at first detected face, return empty if no face.\n",
    "    if len(face) == 1:\n",
    "        facefeatures = face\n",
    "    elif len(face_two) == 1:\n",
    "        facefeatures = face_two\n",
    "    elif len(face_three) == 1:\n",
    "        facefeatures = face_three\n",
    "    elif len(face_four) == 1:\n",
    "        facefeatures = face_four\n",
    "    else:\n",
    "        facefeatures = \"\"\n",
    "\n",
    "    #Cut and save face\n",
    "    for (x, y, w, h) in facefeatures: #get coordinates and size of rectangle containing face\n",
    "        gray = gray[y:y+h, x:x+w] #Cut the frame to size\n",
    "        #print(gray.shape)\n",
    "        try:\n",
    "            out = cv2.resize(gray, (350, 350)) #Resize face so all images have same size\n",
    "            #print(out.shape)\n",
    "        except:\n",
    "            pass #If error, pass file\n",
    "        return out\n",
    "\n",
    "\n",
    "def get_landmarks(image):\n",
    "    '''This function locates facial landmarks and computes the relative distance from the mean for each point.'''\n",
    "   \n",
    "\n",
    "    training_data = []\n",
    "    detections = detector(image, 1)\n",
    "    for k,d in enumerate(detections): #For all detected face instances individually\n",
    "        shape = predictor(image, d) #Draw Facial Landmarks with the predictor class\n",
    "        xlist = []\n",
    "        ylist = []\n",
    "        for i in range(1,68): #Store X and Y coordinates in two lists\n",
    "            xlist.append(float(shape.part(i).x))\n",
    "            ylist.append(float(shape.part(i).y))\n",
    "        xmean = np.mean(xlist)\n",
    "        ymean = np.mean(ylist)\n",
    "        xcentral = [(x-xmean) for x in xlist]\n",
    "        ycentral = [(y-ymean) for y in ylist]\n",
    "        landmarks_vectorised = []\n",
    "        for x, y, w, z in zip(xcentral, ycentral, xlist, ylist):\n",
    "            landmarks_vectorised.append(w)\n",
    "            landmarks_vectorised.append(z)\n",
    "            meannp = np.asarray((ymean,xmean))\n",
    "            coornp = np.asarray((z,w))\n",
    "            dist = np.linalg.norm(coornp-meannp)\n",
    "            landmarks_vectorised.append(dist)\n",
    "            landmarks_vectorised.append((math.atan2(y, x)*360)/(2*math.pi))\n",
    "        data['landmarks_vectorised'] = landmarks_vectorised\n",
    "    if len(detections) < 1:\n",
    "        data['landmarks_vestorised'] = \"error\"\n",
    "       \n",
    "    training_data.append(data['landmarks_vectorised'])\n",
    "    return training_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09650627, 0.0547831 , 0.3746276 , 0.01241157, 0.40252017,\n",
       "        0.05915127]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict_proba(get_landmarks(process_image(path1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "() () () ()\n"
     ]
    }
   ],
   "source": [
    "pic(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
